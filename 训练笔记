训练笔记


input_dim = 6
hidden_dim1 = 100
hidden_dim2 = 150
output_dim = 4
batch_size = 128

loss不降
loss波动1.2-1.4
迭代很快

小网络，loss稳定下降 ，很慢

大网络，loss波动，迭代很快


input_dim = 6
hidden_dim1 = 100
output_dim2 = 4
batch_size = 128
去掉softmax层，波动消失，迭代很快，稳定下降，降至1.38->仍然欠拟合

继续增加隐层神经元个数至1000个，波动消失，迭代很快，稳定下降，降至1.38->仍然欠拟合

由于loss在降，所以考虑网络拟合能力不够，增加一层，隐层输出150个神经元，1.386

由于数据量较少（5w）考虑减小隐层神经元个数，10，15，迭代变慢，稳定下降，降至1.37，有进步#2000轮
由于结束时还在学，所以增大迭代次数至5000，增加一点神经元个数，15，20，希望加快一点速度，又不会因为数据量不够cover不住而影响精度->不好使
改回去，3层，10，15，5000轮，1.34，但是很慢


所以考虑增大数据量（50w），较大隐层神经元个数，4层，100，150，200，5000轮，很慢，跑不动

10w，6层，10，15， 20，30，40，5000，512
深度加深，迭代变块，略微波动，保持下降，降至1.38不动

5w，3层，10，15，128
50000，1.27

5w，4层，100，150，200，128
6层，100，150，200，300，400



看数据
筛特征
调参数
做融合

一对一的准确率
看bad case

feature importance选择特征
1. [100,120,140,all] cv=5 scoring='neg_logloss'
100 is better
submit result:



训练 验证 按照类别 均匀切分-done

保存预测结果，计算类别准确率，看bad case

先测试，再提交，服务器代码与本机代码保持一致-done

整理代码，创建git仓库

从头开始看数据

换上自定义验证函数-done
加上交叉验证
验证线上线下分数一致性、调节参数-done
max_depth:8
eta:0.05
gamma:0.001
min_child_weight:1 #  Minimum sum of instance weight(hessian) needed in a child.
解释：gamma和min_child_weight设置的较小，对树的生长不做过多限制；根据数据量设置max_depth限制
训练过程
2500轮左右auc上涨非常缓慢，大概在千分位上涨

学习新特征